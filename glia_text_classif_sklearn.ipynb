{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "718c9929-b23f-42f3-af88-3727a8e96c10",
   "metadata": {},
   "source": [
    "# Glia - Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "208bcc4b-f678-480f-936c-7be2651afba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6d7995-c4e0-4efe-8441-4e8c9c4168f6",
   "metadata": {},
   "source": [
    "## Read data\n",
    "\n",
    "The dataset consists of 13.8k rows of chatbot messages with the associated label. The dataset is open-source and available on HuggingFace: https://huggingface.co/datasets/Bhuvaneshwari/intent_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97b1a7b4-1d17-4e54-aa5b-737056a453c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>listen to westbam alumb allergic on google music</td>\n",
       "      <td>PlayMusic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>add step to me to the 50 clásicos playlist</td>\n",
       "      <td>AddToPlaylist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i give this current textbook a rating value of...</td>\n",
       "      <td>RateBook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>play the song little robin redbreast</td>\n",
       "      <td>PlayMusic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>please add iris dement to my playlist this is ...</td>\n",
       "      <td>AddToPlaylist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text          label\n",
       "0   listen to westbam alumb allergic on google music      PlayMusic\n",
       "1         add step to me to the 50 clásicos playlist  AddToPlaylist\n",
       "2  i give this current textbook a rating value of...       RateBook\n",
       "3               play the song little robin redbreast      PlayMusic\n",
       "4  please add iris dement to my playlist this is ...  AddToPlaylist"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2858aa-0cab-4698-84c3-b8385efced32",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5898ca5-1fbd-4285-928e-33c7a4a3e786",
   "metadata": {},
   "source": [
    "I am taking a subset of data just to make computation faster. I tried fine-tuning a pretrained Transformer model, but I was running out of memory. Instead, I will take 100 messages per label (12 labels, so a total of 1200 messages), and use scikit-learn to classify each message to the correct intent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a538950c-62c6-47a5-921c-ccf9c7bbce44",
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_df = pd.DataFrame(columns=['text', 'label'])\n",
    "\n",
    "grouped = df.groupby('label')\n",
    "\n",
    "for label, group in grouped:\n",
    "    \n",
    "    if len(group) >= 100:\n",
    "        selected_samples = group.sample(n=100, random_state=42)  \n",
    "    else:\n",
    "        selected_samples = group\n",
    "    \n",
    "    mini_df = pd.concat([mini_df, selected_samples])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bad4da6-90bf-4e10-b86e-e3af66ff0863",
   "metadata": {},
   "source": [
    "There is a label for which there are not 100 messages, so we end up with 1199 messages in total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f219276-68b7-43c1-a3bf-6411589aa48d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1199, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18466428-f38b-46dc-8cdc-699eb3005d3f",
   "metadata": {},
   "source": [
    "Map the intent to a number, so we can train a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c62a8c6-75d0-4ca7-bd7a-171c8c333b7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12633</th>\n",
       "      <td>put corrina  corrina onto my classical x list</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6954</th>\n",
       "      <td>add kd lang to my deep focus playlist</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>add elkie brooks to happy birthday playlist</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>add judge jules to instrumental study</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4052</th>\n",
       "      <td>put beside you in my spotify orchestra cello p...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "12633      put corrina  corrina onto my classical x list      9\n",
       "6954               add kd lang to my deep focus playlist      9\n",
       "825          add elkie brooks to happy birthday playlist      9\n",
       "2732               add judge jules to instrumental study      9\n",
       "4052   put beside you in my spotify orchestra cello p...      9"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intents = list(set(mini_df['label']))\n",
    "\n",
    "id2label = {idx:label for idx, label in enumerate(intents)}\n",
    "label2id = {label:idx for idx, label in enumerate(intents)}\n",
    "\n",
    "mini_df['label'] = mini_df['label'].map(label2id)\n",
    "\n",
    "mini_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99c376d-7d0d-44b9-a268-cb7d3d63e268",
   "metadata": {},
   "source": [
    "## Split the data\n",
    "I will do a 70/30 train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e65d0f8-ca9f-49d9-a859-196021938c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = mini_df['text']\n",
    "y = mini_df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81585051-ec95-4aef-b102-d72b0207a196",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "### Extract features from text\n",
    "\n",
    "Using scikit-learn, I will use the TF-IDF transformation to extract features from the text. That way, we have numerical data to train a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f327f505-b9d7-4f8d-aed8-a91d8dc1d775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(839, 1259)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vect = CountVectorizer()\n",
    "\n",
    "X_train_count = vect.fit_transform(X_train)\n",
    "\n",
    "X_train_count.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c2a0096-0915-47b7-a20a-aa1532d66250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(839, 1259)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "transformer = TfidfTransformer(use_idf=False).fit(X_train_count)\n",
    "\n",
    "X_train_tfidf = transformer.fit_transform(X_train_count)\n",
    "\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673d0804-9410-4367-82f9-8be0682fa9a7",
   "metadata": {},
   "source": [
    "### Baseline classifier\n",
    "\n",
    "I will use a dummy classifier as a baseline model to evaluate more advanced classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae52e37e-fa8d-45ce-aa95-8cd1067a3c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      precision    recall  f1-score   support\n",
      "\n",
      "           excitment       0.14      0.17      0.15        30\n",
      "          GetWeather       0.08      0.07      0.07        30\n",
      "        Cancellation       0.03      0.03      0.03        30\n",
      "         Affirmation       0.13      0.13      0.13        30\n",
      "      BookRestaurant       0.16      0.13      0.15        30\n",
      "           PlayMusic       0.12      0.10      0.11        30\n",
      "SearchScreeningEvent       0.15      0.17      0.16        30\n",
      "  SearchCreativeWork       0.06      0.07      0.06        30\n",
      "        Book Meeting       0.07      0.07      0.07        30\n",
      "       AddToPlaylist       0.05      0.03      0.04        30\n",
      "            RateBook       0.11      0.10      0.11        30\n",
      "           Greetings       0.10      0.13      0.11        30\n",
      "\n",
      "            accuracy                           0.10       360\n",
      "           macro avg       0.10      0.10      0.10       360\n",
      "        weighted avg       0.10      0.10      0.10       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "dummy_clf = DummyClassifier(strategy='uniform', random_state=42)\n",
    "\n",
    "dummy_clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "X_test_count = vect.transform(X_test)\n",
    "X_test_tfidf = transformer.transform(X_test_count)    # Apply the TF-IDF transformation on X_test\n",
    "\n",
    "label_idx = list(id2label.keys())   # Get the id of each label\n",
    "label_names = list(label2id.keys())   # Get the name of each label\n",
    "\n",
    "dummy_preds = dummy_clf.predict(X_test_tfidf)\n",
    "\n",
    "dummy_clf_report = classification_report(y_test, dummy_preds, labels=label_idx, target_names=label_names)\n",
    "\n",
    "print(dummy_clf_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2301dcf-2f11-49c3-804f-ae5bf667c9a4",
   "metadata": {},
   "source": [
    "As expected, the performance of the dummy classifier is very bad, with only 10% in accuracy. Now, let's test a naive Bayes classifier and an SVM (support vector machine) classifier.\n",
    "\n",
    "**Note that I report the accuracy because each intent is present in equal proportions. Otherwise, I would look at the weighted F1-Score**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda1cddb-6a63-42a5-be0e-2e85eef34b60",
   "metadata": {},
   "source": [
    "### Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4e7c418-8e3b-4747-a83a-c6df6d902de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      precision    recall  f1-score   support\n",
      "\n",
      "           excitment       1.00      1.00      1.00        30\n",
      "          GetWeather       0.97      1.00      0.98        30\n",
      "        Cancellation       1.00      1.00      1.00        30\n",
      "         Affirmation       1.00      1.00      1.00        30\n",
      "      BookRestaurant       1.00      0.97      0.98        30\n",
      "           PlayMusic       0.94      0.97      0.95        30\n",
      "SearchScreeningEvent       0.93      0.87      0.90        30\n",
      "  SearchCreativeWork       0.83      0.83      0.83        30\n",
      "        Book Meeting       1.00      1.00      1.00        30\n",
      "       AddToPlaylist       0.97      1.00      0.98        30\n",
      "            RateBook       1.00      1.00      1.00        30\n",
      "           Greetings       1.00      1.00      1.00        30\n",
      "\n",
      "            accuracy                           0.97       360\n",
      "           macro avg       0.97      0.97      0.97       360\n",
      "        weighted avg       0.97      0.97      0.97       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "naive_clf = MultinomialNB()\n",
    "\n",
    "naive_clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "naive_preds = naive_clf.predict(X_test_tfidf)\n",
    "\n",
    "naive_clf_report = classification_report(y_test, naive_preds, labels=label_idx, target_names=label_names)\n",
    "\n",
    "print(naive_clf_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73aae44-f5eb-46b8-a454-45fae9f545d0",
   "metadata": {},
   "source": [
    "Already, the performance is much better, and in fact it is very good, with an accuracy of 97%.\n",
    "\n",
    "**Note that I report the accuracy because each intent is present in equal proportions. Otherwise, I would look at the weighted F1-Score**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03be4bc1-50ee-4773-98d9-af0bb7eae46f",
   "metadata": {},
   "source": [
    "### SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f998e383-e57f-4604-a792-1ffe7b871a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      precision    recall  f1-score   support\n",
      "\n",
      "           excitment       1.00      1.00      1.00        30\n",
      "          GetWeather       0.97      1.00      0.98        30\n",
      "        Cancellation       1.00      1.00      1.00        30\n",
      "         Affirmation       1.00      1.00      1.00        30\n",
      "      BookRestaurant       1.00      0.97      0.98        30\n",
      "           PlayMusic       0.90      0.93      0.92        30\n",
      "SearchScreeningEvent       0.96      0.87      0.91        30\n",
      "  SearchCreativeWork       0.74      0.83      0.78        30\n",
      "        Book Meeting       1.00      0.97      0.98        30\n",
      "       AddToPlaylist       1.00      1.00      1.00        30\n",
      "            RateBook       0.97      0.93      0.95        30\n",
      "           Greetings       1.00      1.00      1.00        30\n",
      "\n",
      "            accuracy                           0.96       360\n",
      "           macro avg       0.96      0.96      0.96       360\n",
      "        weighted avg       0.96      0.96      0.96       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "sv_clf = SVC()\n",
    "\n",
    "sv_clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "sv_preds = sv_clf.predict(X_test_tfidf)\n",
    "\n",
    "sv_clf_report = classification_report(y_test, sv_preds, labels=label_idx, target_names=label_names)\n",
    "\n",
    "print(sv_clf_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fd50c3-035f-4151-ac28-997e3af9d645",
   "metadata": {},
   "source": [
    "The SVM classifier performs really well too, but its accuracy is lower than the Naive Bayes model (96 vs 97). Therefore, the Naive Bayes model is the best option for this scenario.\n",
    "\n",
    "**Note that I report the accuracy because each intent is present in equal proportions. Otherwise, I would look at the weighted F1-Score**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b311fde2-ca58-46ff-8160-e7b7812ccb97",
   "metadata": {},
   "source": [
    "## Train a pipeline and save the model\n",
    "\n",
    "Now, I create a pipeline for the model to classifiy new text and to deploy it through a REST API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a696115-3ea2-4dcb-b744-c2e8043332a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()), (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
       "                (&#x27;clf&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()), (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
       "                (&#x27;clf&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfTransformer</label><div class=\"sk-toggleable__content\"><pre>TfidfTransformer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
       "                ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "intent_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB())\n",
    "])\n",
    "\n",
    "intent_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17dba3b-6ca3-4c7c-823c-066607251326",
   "metadata": {},
   "source": [
    "#### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cdf905d2-2aa3-4236-bc2f-84af56621a21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['intent_clf.joblib']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "\n",
    "dump(intent_clf, 'intent_clf.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7db16b88-3cf0-4243-acf8-d24bc3a47b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'excitment',\n",
       " 1: 'GetWeather',\n",
       " 2: 'Cancellation',\n",
       " 3: 'Affirmation',\n",
       " 4: 'BookRestaurant',\n",
       " 5: 'PlayMusic',\n",
       " 6: 'SearchScreeningEvent',\n",
       " 7: 'SearchCreativeWork',\n",
       " 8: 'Book Meeting',\n",
       " 9: 'AddToPlaylist',\n",
       " 10: 'RateBook',\n",
       " 11: 'Greetings'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3247fe5f-0369-4ae5-bd3b-184e958dd346",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05753105-d861-44e2-9e36-54fd1c62f578",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891579b9-8baf-45e3-b834-261f2f5bc92e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b343b59-91b0-46c5-8b54-51d56d4fa494",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
